{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aless\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aless\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\aless\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "from nltk.stem import WordNetLemmatizer #lemitization\n",
    "from nltk.corpus import words\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/processed/processed_xy_augmented.csv')\n",
    "change_in_pop = data['test_mean_clicks'].div(data['test_mean_impressions'])-data['clicks'].div(data['impressions'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotional_score(data,emotion,length):\n",
    "    lengths = data[length].apply(lambda x: log2(x+1))\n",
    "    return data[emotion].div(lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1.477829\n",
      "1        1.477829\n",
      "2        1.477829\n",
      "3        0.000000\n",
      "4        0.000000\n",
      "           ...   \n",
      "29797    0.000000\n",
      "29798    0.000000\n",
      "29799    0.000000\n",
      "29800    0.000000\n",
      "29801    0.000000\n",
      "Length: 29802, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(emotional_score(data,'Negative','token_word_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualize(data,emotion,length,y):\n",
    "    escore= emotional_score(data,emotion,length)\n",
    "    sns.regplot(x=escore,y=y)\n",
    "    plt.savefig(f'../../data/visualizations/{emotion}-{length}.png')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in ['Positive','Negative','Anger','Anticipation','Disgust','Fear','Joy','Sadness','Surprise','Trust']:\n",
    "    for length in ['token_word_count','emotive_word_count']:\n",
    "        vizualize(data,emotion,length,change_in_pop)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93de652a13d3233f39edb71dbfe42b78ce309ddee1c3b3e0d4d5db9e0e0c877c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
